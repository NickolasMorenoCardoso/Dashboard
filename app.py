# cp1_uber_dashboard_multitab.py
# Execu√ß√£o: streamlit run cp1_uber_dashboard_multitab.py

import textwrap
from typing import List, Tuple
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
from scipy import stats
from PIL import Image
from pathlib import Path

# =========================
# CONFIG (tem que ser a 1¬™ chamada Streamlit e s√≥ 1x)
# =========================
st.set_page_config(page_title="CP1 ‚Äì Dashboard Profissional + An√°lise de Dados", layout="wide")

st.title("CP1 - Backlog: DATA SCIENCE And STATISTICAL COMPUTING")

# =========================
# --------- ABAS ----------
# =========================
tabs = st.tabs(["üè† Home", "üéì Forma√ß√£o e Experi√™ncia", "üõ† Skills", "üìä An√°lise Uber"])

# =========================
# Fun√ß√µes auxiliares (usadas na aba 4)
# =========================
def infer_types(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for col in df.columns:
        lc = col.lower()
        if lc in {"date", "data"}:
            df[col] = pd.to_datetime(df[col], errors="coerce")
        elif lc in {"time", "hora"}:
            df[col] = pd.to_datetime(df[col], errors="coerce").dt.time
        elif any(k in lc for k in ["distance", "value", "avg", "rating", "fare", "km", "amount"]):
            df[col] = pd.to_numeric(df[col], errors="coerce")
    return df

def basic_schema(df: pd.DataFrame) -> pd.DataFrame:
    info = []
    for col in df.columns:
        s = df[col]
        info.append({
            "coluna": col,
            "tipo": str(s.dtype),
            "ausentes": int(s.isna().sum()),
            "#valores_unicos": int(s.nunique(dropna=True)),
            "exemplos": ", ".join(map(lambda x: str(x)[:25], s.dropna().unique()[:6]))
        })
    return pd.DataFrame(info)

def proportion_confint_wilson(successes: int, nobs: int, alpha: float = 0.05) -> Tuple[float, float]:
    if nobs == 0:
        return (np.nan, np.nan)
    z = stats.norm.ppf(1 - alpha / 2)
    phat = successes / nobs
    denom = 1 + z**2 / nobs
    centre = phat + z**2/(2*nobs)
    margin = z*np.sqrt((phat*(1-phat) + z**2/(4*nobs))/nobs)
    return ((centre - margin)/denom, (centre + margin)/denom)

def mean_confint_t(data: pd.Series, alpha: float = 0.05) -> Tuple[float, float, float, int]:
    data = pd.to_numeric(data, errors="coerce").dropna()
    n = len(data)
    if n < 2:
        return (np.nan, np.nan, np.nan, n)
    mean = data.mean()
    sd = data.std(ddof=1)
    se = sd / np.sqrt(n)
    tcrit = stats.t.ppf(1 - alpha/2, df=n-1)
    return (mean, mean - tcrit*se, mean + tcrit*se, n)

def choose_numeric_columns(df: pd.DataFrame) -> List[str]:
    return [c for c in df.select_dtypes(include=["number", "float", "int"]).columns if df[c].notna().sum() > 0]

def choose_categorical_columns(df: pd.DataFrame, max_card: int = 40) -> List[str]:
    cats = []
    for c in df.columns:
        if df[c].dtype == "object" or df[c].dtype.name == "category":
            if df[c].nunique(dropna=True) <= max_card:
                cats.append(c)
    return cats

def clean_booking_status(s: pd.Series) -> pd.Series:
    def map_status(x):
        if pd.isna(x): return np.nan
        x = str(x).strip().lower()
        if "complete" in x: return "Completed"
        if "customer" in x and "cancel" in x: return "Cancelled by Customer"
        if "driver" in x and "cancel" in x: return "Cancelled by Driver"
        if "incomplete" in x: return "Incomplete"
        return x.title()
    return s.apply(map_status)

# =========================
# ABA 1: Home
# =========================
with tabs[0]:
    st.title("üè† Home")
    img_path = Path("M√≠dia.jpg")
    if img_path.exists():
        st.image(Image.open(img_path), caption="Minha Imagem", width=150)
    else:
        st.warning("Imagem 'M√≠dia.jpg' n√£o encontrada na pasta do app.")
    st.markdown(
        """
        **Apresenta√ß√£o:**

        - Meu nome √© Nickolas, tenho 19 anos e estou no segundo ano do Ensino Superior cursando Engenharia de Software na Fiap.
        - Este projeto √© um dashboard interativo em Streamlit que tamb√©m serve como portf√≥lio.
        - Abas: Introdu√ß√£o ‚Ä¢ Forma√ß√£o/Experi√™ncias ‚Ä¢ Soft Skills ‚Ä¢ **An√°lise de dados da Uber**.
        """
    )

# =========================
# ABA 2: Forma√ß√£o e Experi√™ncia
# =========================
with tabs[1]:
    st.title("üéì Forma√ß√£o e Experi√™ncia")
    st.markdown(
        """
        **Forma√ß√£o Acad√™mica:**
        - Ensino M√©dio T√©cnico <TI> - <Senac>
        - Curso Superior <Engenharia de Software> ‚Äì <Fiap> (2024-2027)
        - Cursos Online relevantes: <Cultura Ingl√™sa>, <SAGA>
        
        **Experi√™ncias:**
        - Projeto Tech Mahindra (Fiap/2024) ‚Äì Website e propostas de melhoria, com apresenta√ß√£o √† empresa parceira.
        - Desafio Lixo Eletr√¥nico (Senac/2023) ‚Äì Turma vencedora; 519 kg coletados por mim (total 746,8 kg).
        - ONU ‚Äì COP Geopol√≠tica das √Åguas (Senac/2023) ‚Äì Simula√ß√£o representando a Rep√∫blica do Qu√™nia.
        """
    )

# =========================
# ABA 3: Skills
# =========================
with tabs[2]:
    st.title("üõ† Skills")
    skills = {
        "Habilidade": [
            "Microsoft Office","L√≥gica de Programa√ß√£o","Python","SQL","Java","JavaScript",
            "Trabalho em Equipe","Pontualidade","Proatividade","Organiza√ß√£o","Power BI","Ingl√™s",
            "Front-End","Back-End","Html","Cisco Packet Tracer","Comunica√ß√£o","Visual Studio Code","IntelliJ"
        ],
        "Categoria": [
            "Desenvolvimento","Programa√ß√£o","Programa√ß√£o","Desenvolvimento","Programa√ß√£o","Programa√ß√£o",
            "Pessoal","Pessoal","Pessoal","Pessoal","Desenvolvimento","Pessoal","Programa√ß√£o","Programa√ß√£o",
            "Programa√ß√£o","Desenvolvimento","Pessoal","Desenvolvimento","Desenvolvimento"
        ],
        "N√≠vel (autoavalia√ß√£o)": [6,7,6,7,8,8,8,9,8,8,5,10,6,6,6,9,10,7,7]
    }
    df_skills = pd.DataFrame(skills)
    st.subheader("üìã Lista de Habilidades")
    st.dataframe(df_skills)

# =========================
# ABA 4: An√°lise Uber (CSV carregado automaticamente)
# =========================
# -------------------------
# Leitura do CSV
# -------------------------
DATA_PATHS = [Path("uber.csv"), Path("./uber.csv"), Path("/mnt/data/uber.csv")]
csv_path = next((p for p in DATA_PATHS if p.exists()), None)

if csv_path is None:
    st.error("Arquivo 'uber.csv' n√£o encontrado. Coloque o arquivo na mesma pasta do script ou em /mnt/data/uber.csv")
    st.stop()

df_raw = pd.read_csv(csv_path, encoding="utf-8")
# c√≥pia que vamos manipular
df = df_raw.copy()

# -------------------------
# Fun√ß√µes utilit√°rias
# -------------------------
def infer_types(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for col in df.columns:
        lc = col.lower()
        if lc in {"date", "data"}:
            df[col] = pd.to_datetime(df[col], errors="coerce")
        elif lc in {"time", "hora"}:
            df[col] = pd.to_datetime(df[col], errors="coerce").dt.time
        elif any(k in lc for k in ["distance", "value", "avg", "rating", "fare", "km", "amount", "booking value", "ride distance"]):
            df[col] = pd.to_numeric(df[col], errors="coerce")
    return df

def clean_booking_status(s: pd.Series) -> pd.Series:
    def map_status(x):
        if pd.isna(x): return np.nan
        x = str(x).strip().lower()
        if "complete" in x: return "Completed"
        if "no driver" in x or "no_driver" in x: return "No Driver Found"
        if "incomplete" in x: return "Incomplete"
        if "cancel" in x and "customer" in x: return "Cancelled by Customer"
        if "cancel" in x and "driver" in x: return "Cancelled by Driver"
        return x.title()
    return s.apply(map_status)

def choose_numeric_columns(df: pd.DataFrame):
    return [c for c in df.select_dtypes(include=["number"]).columns if df[c].notna().sum() > 0]

# -------------------------
# Pr√©-processamento
# -------------------------
df = infer_types(df)

# padroniza Booking Status se existir coluna com esse nome (ou varia√ß√µes)
possible_status_cols = [c for c in df.columns if c.lower().strip() in ("booking status", "status", "booking_status")]
if possible_status_cols:
    st_col = possible_status_cols[0]
    df[st_col] = clean_booking_status(df[st_col]).astype("category")
    booking_status_col = st_col
else:
    booking_status_col = None

# -------------------------
# UI / Layout
# -------------------------
st.title("üìä An√°lise Uber 2024 ‚Äî Efici√™ncia Log√≠stica & Aspectos Financeiros")
st.caption(f"Arquivo usado: {csv_path} ‚Äî registros: {len(df):,}")

tabs = st.tabs(["üèÅ Introdu√ß√£o", "üö¶ Efici√™ncia Log√≠stica", "üí∞ Aspectos Financeiros"])

# -------------------------
# Aba: Introdu√ß√£o
# -------------------------
with tabs[0]:
    st.header("Resumo do dataset")

    st.markdown(
        """
        **Introdu√ß√£o:**

        O presente estudo tem como objetivo analisar um conjunto de dados de corridas da Uber, explorando aspectos que impactam diretamente tanto a efici√™ncia log√≠stica quanto o desempenho financeiro da plataforma.
        A an√°lise ser√° dividida em dois eixos principais:
        Efici√™ncia Log√≠stica ‚Äì avaliando fatores que influenciam a opera√ß√£o, como taxas de cancelamento, indisponibilidade de motoristas, tempos m√©dios de atendimento (VTAT) e de deslocamento at√© o cliente (CTAT), al√©m dos principais motivos de falhas nas corridas. Esse eixo busca compreender como a Uber pode otimizar sua malha de motoristas, reduzir falhas operacionais e aumentar a confiabilidade do servi√ßo.
        Aspectos Financeiros ‚Äì investigando o comportamento do faturamento das corridas, valores m√©dios por tipo de ve√≠culo, rela√ß√£o entre dist√¢ncia percorrida e valor pago, al√©m das prefer√™ncias de m√©todos de pagamento utilizados pelos clientes. Esse eixo permitir√° identificar padr√µes de receita, ticket m√©dio e potenciais perdas financeiras relacionadas a cancelamentos e corridas incompletas.
        Com essa abordagem, ser√° poss√≠vel n√£o apenas compreender como os fatores log√≠sticos impactam diretamente a qualidade do servi√ßo, mas tamb√©m como esses elementos se refletem na sustentabilidade financeira da opera√ß√£o.
        """
    )

    st.markdown(f"- Registros: **{len(df):,}**\n- Colunas: **{len(df.columns)}**")
    st.markdown("Colunas principais detectadas:")
    st.dataframe(pd.DataFrame({
        "coluna": df.columns,
        "tipo_detectado": [str(df[c].dtype) for c in df.columns],
        "nulos": [int(df[c].isna().sum()) for c in df.columns]
    }).reset_index(drop=True))

# -------------------------
# Aba: Efici√™ncia Log√≠stica
# -------------------------
with tabs[1]:
    st.header("üö¶ Efici√™ncia Log√≠stica")
    # status geral
    if booking_status_col:
        st.subheader("Taxa de Atendimento (Status das corridas)")
        counts = df[booking_status_col].value_counts(dropna=False)
        fig = px.pie(values=counts.values, names=counts.index, title="Distribui√ß√£o por Booking Status")
        st.plotly_chart(fig, use_container_width=True)

    # motivos de cancelamento (cliente / driver)
    st.subheader("Principais motivos de cancelamento / incompletude")
    # tenta detectar colunas de motivo com nomes comuns
    motivo_cols = [c for c in df.columns if "reason" in c.lower() or "cancel" in c.lower() and "reason" in c.lower()]
    if len(motivo_cols) == 0:
        # fallback por nomes vistos no CSV
        for name in ["Reason for cancelling by Customer","Driver Cancellation Reason","Reason for Incomplete Rides","Reason for Cancelled Rides by Customer"]:
            if name in df.columns:
                motivo_cols.append(name)
    for col in motivo_cols:
        top = df[col].dropna().value_counts().head(8)
        if len(top) > 0:
            st.markdown(f"**{col}** (top motivos)")
            fig = px.bar(top, x=top.index, y=top.values, labels={'x':'Motivo','y':'Qtd'})
            fig.update_layout(xaxis_tickangle= -45)
            st.plotly_chart(fig, use_container_width=True)

    # VTAT / CTAT
    st.subheader("Tempos VTAT / CTAT (chegada do ve√≠culo e deslocamento)")
    vt_col = next((c for c in df.columns if "vtat" in c.lower()), None)
    ct_col = next((c for c in df.columns if "ctat" in c.lower()), None)
    if vt_col and ct_col:
        st.markdown(f"Colunas usadas: **{vt_col}**, **{ct_col}**")
        st.plotly_chart(px.box(df[[vt_col, ct_col]].melt(var_name="tipo", value_name="tempo").dropna(),
                               x="tipo", y="tempo", title="Distribui√ß√£o VTAT vs CTAT"), use_container_width=True)
        st.dataframe(df[[vt_col, ct_col]].describe().T)
    else:
        st.info("Colunas VTAT/CTAT n√£o encontradas no dataset.")

    # Cancelamentos por Vehicle Type (se existir)
    veh_col = next((c for c in df.columns if "vehicle" in c.lower()), None)
    if veh_col and booking_status_col:
        st.subheader("Cancelamentos por tipo de ve√≠culo")
        df_cancel = df[df[booking_status_col] != "Completed"]
        if len(df_cancel) > 0:
            counts = df_cancel[veh_col].value_counts().head(20)
            st.plotly_chart(px.bar(counts, x=counts.index, y=counts.values, title="Cancelamentos por Vehicle Type"), use_container_width=True)
        else:
            st.info("Sem registros de cancelamento para plotar.")

    # padr√µes por hor√°rio (se existir Date/Time)
    date_col = next((c for c in df.columns if c.lower() in ("date", "data")), None)
    time_col = next((c for c in df.columns if c.lower() in ("time", "hora")), None)
    if date_col:
        st.subheader("Padr√µes por dia da semana / hor√°rio")
        df['_date'] = pd.to_datetime(df[date_col], errors="coerce")
        if df['_date'].notna().any():
            df['_dow'] = df['_date'].dt.day_name()
            agg = df.groupby('_dow')[booking_status_col].apply(lambda s: (s=="Completed").mean() if booking_status_col else np.nan).sort_index()
            st.markdown("**Taxa de conclus√£o por dia da semana (propor√ß√£o conclu√≠da)**")
            st.plotly_chart(px.bar(agg, x=agg.index, y=agg.values, labels={'x':'Dia','y':'Propor√ß√£o Conclu√≠da'}), use_container_width=True)
        df.drop(columns=['_date','_dow'], errors='ignore')

# -------------------------
# Aba: Aspectos Financeiros
# -------------------------
with tabs[2]:
    st.header("üí∞ Aspectos Financeiros")
    # Booking Value e Ride Distance
    bk_col = next((c for c in df.columns if "booking" in c.lower() and "value" in c.lower()), "Booking Value" if "Booking Value" in df.columns else None)
    dist_col = next((c for c in df.columns if "distance" in c.lower()), "Ride Distance" if "Ride Distance" in df.columns else None)

    if bk_col and bk_col in df.columns:
        st.subheader("Distribui√ß√£o do valor das corridas")
        st.plotly_chart(px.histogram(df, x=bk_col, nbins=40, title="Booking Value Distribution").update_layout(xaxis_title="Valor"), use_container_width=True)
        st.dataframe(df[bk_col].describe().T)

    if bk_col in df.columns and dist_col in df.columns:
        st.subheader("Correla√ß√£o: Dist√¢ncia x Valor")
        st.plotly_chart(px.scatter(df, x=dist_col, y=bk_col, trendline="ols", title="Ride Distance vs Booking Value"), use_container_width=True)
        corr = df[[dist_col, bk_col]].corr().iloc[0,1]
        st.markdown(f"**Correla√ß√£o pearson (dist√¢ncia, valor):** {corr:.3f}")

    # Ticket m√©dio por vehicle type
    if veh_col and bk_col in df.columns:
        st.subheader("Ticket m√©dio por tipo de ve√≠culo")
        ticket = df.groupby(veh_col)[bk_col].mean().sort_values(ascending=False).dropna()
        st.plotly_chart(px.bar(ticket, x=ticket.index, y=ticket.values, title="Ticket M√©dio por Vehicle Type"), use_container_width=True)

    # M√©todos de pagamento
    pay_col = next((c for c in df.columns if "payment" in c.lower()), None)
    if pay_col:
        st.subheader("M√©todos de pagamento")
        pay = df[pay_col].value_counts(normalize=True).mul(100).round(2)
        st.plotly_chart(px.pie(values=pay.values, names=pay.index, title="Distribui√ß√£o de M√©todos de Pagamento (%)"), use_container_width=True)
        st.dataframe(pay)

    # Receita perdida (corridas n√£o conclu√≠das)
    if bk_col in df.columns and booking_status_col:
        lost = df.loc[df[booking_status_col] != "Completed", bk_col].sum(min_count=1)
        st.metric("Receita estimada perdida (corridas n√£o conclu√≠das)", f"{lost:,.2f}")